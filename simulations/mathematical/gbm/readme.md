
The `Boosted Trees` Paper provides an in depth mathematical grounding for one to understand the underlying xgb(gradient boosting tree)
algorithim. (Most Frequently used model) Please Read the Paper & Create a PR to answer the subsequent Questions. 

[Boosted Trees - TQChen](http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf)
  * [Fei's Talk on paper](https://www.youtube.com/watch?v=031j956LzII)(helpfull)

#### Helpful Additional references
  * [xgboost algorithim](https://www.youtube.com/watch?v=X47SGnTMZIU) by an author (Tong He)

*Simulation Challenge* (Create a PR with answers to be reviewed by guardian). Reference Fei Ye on PR or can use as resource  
1) Are Trees sensetive to scaling or monotonic transformations? (Why or why Not)  
2) Explain how the trees are grown in the context of Information Gain  
3) Where within the GBM algorithim does one Impose an L1/L2 Regularization.  
4) Explain how the Gradient & Hassien is used within the algorithim.    
5) Within the Helper Sheet try to aid others technical understanding of the algorithim. 
   Add any Insights you found especially useful that yielded a breakthrough in your understanding. 
   Can be a detailed mathematical proof or a simple diagram, human explanation, analogy, etc.  
6) When do you stop training each tree and adding more trees to the forest?
7) What are the hyper parameters to tune for tree-based method?
  
TODO: Ask FEI Fei Ye for a few good Q to show deep understanding. 
